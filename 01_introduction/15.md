# 批处理策略

为了辅助批处理系统的设计和实现、应该通过结构示意图和代码实例的形式为设计师和程序员提供基础的批处理程序构建模块和以及处理模式。
在设计批处理Job时,应该将业务逻辑分解成一系列的步骤,使每个步骤都可以利用以下的标准构建模块来实现:


- 转换程序(Conversion Applications): 由外部系统提供或需要写入到外部系统的各种类型的文件,我们都需要为其创建一个转换程序, 用来将所提供的事务记录转换成符合要求的标准格式。这种类型的批处理程序可以部分或全部由转换工具模块组成(translation utility modules)(参见 Basic Batch Services,基本批处理服务)。
- 验证程序(Validation Applications): 验证程序确保所有输入/输出记录都是正确和一致的。验证通常基于文件头和结尾信息, 校验和(checksums)以及记录级别的交叉验证算法。
- 提取程序(Extract Applications): 这种程序从数据库或输入文件读取一堆记录,根据预定义的规则选取记录,并将选取的记录写入到输出文件。
- 提取/更新程序(Extract/Update Applications): 这种程序从数据库或输入文件读取记录,并将输入的每条记录都更新到数据库,或记录到输出文件。
- 处理和更新程序(Processing and Updating Applications): 这种程序对从 提取或验证程序 传过来的输入事务记录进行处理。这些处理通常包括 从数据库读取数据,有可能更新数据库,并创建输出记录。
- 输出/格式化程序(Output/Format Applications): 这种程序从输入文件中读取信息,将数据重组成为标准格式,并打印到输出文件,或者传输给另一个程序或系统。

因为业务逻辑不能用上面介绍的这些标准模块来完成, 所以还需要另外提供一个基本的程序外壳(application shell)。

除了这些主要的模块,每个应用还可以使用一到多个标准的实用程序环节(standard utility steps),如:

- Sort 排序,排序程序从输入文件读取记录,并根据记录中的某个key字段重新排序,然后生成输出文件. 排序通常由标准的系统实用程序来执行.
- Split 拆分,拆分程序从单个输入文件中读取记录,根据某个字段的值,将记录写入到不同的输出文件中. 拆分可以自定义或者由参数驱动的(parameter-driven)系统实用程序来执行.
- Merge 合并,合并程序从多个输入文件读取记录,并将组合后的数据写入到单个输出文件中. 合并可以自定义或者由参数驱动的(parameter-driven)系统实用程序来执行.


批处理程序也可以根据输入来源分类:


- 数据库驱动(Database-driven)的应用程序, 由从数据库中获取的行或值驱动。
- 文件驱动(File-driven)的应用程序,是由从文件中获取的值或记录驱动的。
- 消息驱动(Message-driven)的应用程序由从消息队列中检索到的消息驱动。


所有批处理系统的基础都是处理策略。影响策略选择的因素包括: 预估的批处理系统容量,  在线并发或与另一个批处理系统的并发量, 可用的批处理时间窗口(随着越来越多的企业想要全天候(7x24小时)运转,所以基本上没有明显的批处理时间窗口)。

典型的批处理选项包括:

- 在一个批处理窗口中执行常规离线批处理
- 并发批处理/在线处理
- 同一时刻有许多不同的批处理(runs or jobs)在并行执行
- 分片(即同一时刻,有多个实例在处理同一个job)
- 上面这些的组合


上面列表中的顺序代表了批处理实现复杂性的排序,在同一个批处理窗口的处理最简单,而分片实现最复杂。

商业调度器可能支持上面的部分/或所有类型。


下面的部分将详细讨论这些处理选项。需要特别注意的是, 批处理所采用的提交和锁定策略将依赖于处理执行的类型,作为最佳实践,在线锁策略应该使用相同的原则。因此,在设计批处理整体架构时不能简单地拍脑袋决定(译注:即需要详细的论证和分析)。

锁策略可以只使用普通的数据库锁,也可以在架构中实现自定义的锁服务。锁服务将跟踪数据库锁定(例如在一个专用的数据库表(db-table)中存储必要的信息),然后在应用程序请求数据库操作时授予权限或拒绝。重试逻辑也可以通过这种架构实现,以避免批处理作业因为资源锁定的情况而失败。


** 1。在一个批处理窗口中的常规处理** 对于运行在一个单独批处理窗口中的简单批处理,更新的数据对在线用户或其他批处理来说并没有实时性要求,也没有并发问题,在批处理运行完成后执行单次提交即可。

大多数情况下,一种更健壮的方法会更合适。要记住的一件事是,批处理系统会随着时间的流逝而增长,包括复杂度和需要处理的数据量。如果没有合适的锁定策略,系统仍然依赖于一个单一的提交点,则修改批处理程序会是一件痛苦的事情。因此,即使是最简单的批处理系统,也应该为重启-恢复(restart-recovery)选项考虑提交逻辑,更不用说下面涉及到的那些更复杂情况下的信息。


** 2.并发批处理/在线处理 ** 批处理程序处理的数据如果会同时被在线用户更新,就不应该锁定在线用户需要的所有任何数据(不管是数据库还是文件),即使只需要锁定几秒钟的时间。还应该每处理一批事务就提交一次数据库。这减少了其他程序不可用的数据,也压缩了数据不可用的时间。

减少物理锁的另一个选择是实现一个行级的逻辑锁,通过使用乐观锁模式或悲观锁模式。


- 乐观锁假设记录争用的可能性很低。这通常意味着并发批处理和在线处理所使用的每个数据表中都有一个时间戳列。当程序读取一行进行处理时,同时也获得对应的时间戳。当程序处理完该行以后尝试更新时,在update操作的WHERE子句中使用原来的时间戳作为条件。如果时间戳相匹配,则数据和时间戳都更新成功。如果时间戳不匹配,这表明在本程序上次获取和此次更新这段时间内已经有另一个程序修改了同一条记录,因此更新不会被执行。

- 悲观锁定策略假设记录争用的可能性很高,因此在检索时需要获得一个物理锁或逻辑锁。有一种悲观逻辑锁在数据表中使用一个专用的lock-column列。当程序想要为更新目的而获取一行时,它在lock column上设置一个标志。如果为某一行设置了标志位,其他程序在试图获取同一行时将会逻辑上获取失败。当设置标志的程序更新该行时,它也同时清除标志位,允许其他程序获取该行。请注意,在初步获取和初次设置标志位这段时间内必须维护数据的完整性,比如使用数据库锁(eg., SELECT FOR UPDATE)。还请注意,这种方法和物理锁都有相同的缺点,除了它在构建一个超时机制时比较容易管理,比如记录而用户去吃午餐了,则超时时间到了以后锁会被自动释放。


# !!!下面的内容需要整理

These patterns are not necessarily suitable for batch processing, but they might be used for concurrent batch and on-line processing (e.g. in cases where the database doesn't support row-level locking). As a general rule, optimistic locking is more suitable for on-line applications, while pessimistic locking is more suitable for batch applications. Whenever logical locking is used, the same scheme must be used for all applications accessing data entities protected by logical locks.

这些模式并不一定适用于批处理,但他们可能会被用于并发批处理和在线处理的情况下(例如,数据库不支持行级锁定)。作为一般规则,乐观锁定更适合在线应用程序,而悲观锁定更适合批处理应用程序。每当使用逻辑锁定,同样的方案必须用于所有应用程序访问数据实体保护逻辑锁。

Note that both of these solutions only address locking a single record. Often we may need to lock a logically related group of records. With physical locks, you have to manage these very carefully in order to avoid potential deadlocks. With logical locks, it is usually best to build a logical lock manager that understands the logical record groups you want to protect and can ensure that locks are coherent and non-deadlocking. This logical lock manager usually uses its own tables for lock management, contention reporting, time-out mechanism, etc.

请注意,这两个解决方案只有地址锁定单个记录。我们经常需要锁定一组逻辑相关的记录。与物理锁,你必须非常仔细地管理这些为了避免潜在的死锁。与逻辑锁,它通常是最好建立一个理解的逻辑锁管理器逻辑记录组你想保护,可以确保连贯和non-deadlocking锁。这种逻辑锁管理器通常使用自己的表锁管理、争用报告、超时机制,等等。


**3. Parallel Processing** Parallel processing allows multiple batch runs / jobs to run in parallel to minimize the total elapsed batch processing time. This is not a problem as long as the jobs are not sharing the same files, db-tables or index spaces. If they do, this service should be implemented using partitioned data. Another option is to build an architecture module for maintaining interdependencies using a control table. A control table should contain a row for each shared resource and whether it is in use by an application or not. The batch architecture or the application in a parallel job would then retrieve information from that table to determine if it can get access to the resource it needs or not.

** 3。并行处理** 并行处理允许多个批处理运行/工作并行运行批处理总运行时间降到最低。这并不是一个问题,只要工作不共享相同的文件,db-tables或索引空间。如果他们这样做,这个服务应该使用分区数据实现的。另一个选择是构建一个架构模块使用控制表维护相互依赖关系。连续控制表应该包含为每个共享资源和是否在使用一个应用程序。批处理架构或应用程序在并行作业将检索信息的表,以确定是否可以获得所需的资源。

If the data access is not a problem, parallel processing can be implemented through the use of additional threads to process in parallel. In the mainframe environment, parallel job classes have traditionally been used, in order to ensure adequate CPU time for all the processes. Regardless, the solution has to be robust enough to ensure time slices for all the running processes.

如果数据访问并不是一个问题,并行处理可以实现通过使用额外的线程并行处理。在大型机环境中,并行作业类传统上被使用,以确保足够的CPU时间的进程。无论如何,解决方案必须足够强劲,能够确保所有正在运行的进程的时间片。

Other key issues in parallel processing include load balancing and the availability of general system resources such as files, database buffer pools etc. Also note that the control table itself can easily become a critical resource.

其他关键问题并行处理包括负载平衡和一般的可用性系统资源(如文件、数据库缓冲池等。还要注意控制表本身可以很容易地成为一个至关重要的资源。


**4. Partitioning** Using partitioning allows multiple versions of large batch applications to run concurrently. The purpose of this is to reduce the elapsed time required to process long batch jobs. Processes which can be successfully partitioned are those where the input file can be split and/or the main database tables partitioned to allow the application to run against different sets of data.

** 4。分片**使用分区允许多个版本的批处理应用程序并发地运行。这样做的目的是减少过程所需的时间长的批处理作业。流程可以成功分区是那些输入文件可以分裂和/或主要数据库表分区允许应用程序运行在不同的数据。

In addition, processes which are partitioned must be designed to only process their assigned data set. A partitioning architecture has to be closely tied to the database design and the database partitioning strategy. Please note, that the database partitioning doesn't necessarily mean physical partitioning of the database, although in most cases this is advisable. The following picture illustrates the partitioning approach:

此外,过程只分区必须设计过程的分配数据集。一个分区结构是密切相关的数据库设计和数据库分区策略。请注意,数据库分区并不一定意味着物理分区的数据库,尽管在大多数情况下这是明智的。下面的图片展示了分区的方法:

The architecture should be flexible enough to allow dynamic configuration of the number of partitions. Both automatic and user controlled configuration should be considered. Automatic configuration may be based on parameters such as the input file size and/or the number of input records.

体系结构应该足够灵活,允许动态配置分区的数量。自动控制和用户配置应考虑。自动配置等参数可能是基于输入文件大小和/或输入记录的数量。


**4.1 Partitioning Approaches** The following lists some of the possible partitioning approaches. Selecting a partitioning approach has to be done on a case-by-case basis.

** 4.1分区方法 ** 下面列出了一些可能的分区方法。选择一个分区方法要根据具体情况来完成。


*1. Fixed and Even Break-Up of Record Set*

* 1。固定的记录集甚至解体 *

This involves breaking the input record set into an even number of portions (e.g. 10, where each portion will have exactly 1/10th of the entire record set). Each portion is then processed by one instance of the batch/extract application.

这涉及到打破纪录输入偶数的部分(例如10,每个部分都有完全的整个记录集)。每个部分由一个处理批处理/提取应用程序的实例。

In order to use this approach, preprocessing will be required to split the recordset up. The result of this split will be a lower and upper bound placement number which can be used as input to the batch/extract application in order to restrict its processing to its portion alone.

为了使用这种方法,预处理需要将记录集。分裂的结果将是一个最大值和最小位置数值,可以用作输入批处理/提取应用程序为了限制其处理部分。

Preprocessing could be a large overhead as it has to calculate and determine the bounds of each portion of the record set.

预处理可能是一个巨大的开销,因为它必须计算确定的每个部分的记录集。


*2. Breakup by a Key Column*

* 2。键列分手 *

This involves breaking up the input record set by a key column such as a location code, and assigning data from each key to a batch instance. In order to achieve this, column values can either be

这涉及到分手的输入记录键列如位置代码,从每个关键和分配数据批处理实例。为了达到这个目标,可以是列值

*3. Assigned to a batch instance via a partitioning table (see below for details).*

* 3。分配给一个批处理实例通过分区表(详情见下文)。*

*4. Assigned to a batch instance by a portion of the value (e.g. values 0000-0999, 1000 - 1999, etc.)*

* 4。部分分配给一个批处理实例的值(例如值0000 - 0999、1000 - 1999、等等)*



Under option 1, addition of new values will mean a manual reconfiguration of the batch/extract to ensure that the new value is added to a particular instance.

根据选项1,添加新值将意味着手工重新配置批/提取,以确保新的值被添加到一个特定的实例。

Under option 2, this will ensure that all values are covered via an instance of the batch job. However, the number of values processed by one instance is dependent on the distribution of column values (i.e. there may be a large number of locations in the 0000-0999 range, and few in the 1000-1999 range). Under this option, the data range should be designed with partitioning in mind.

选项2下,这将确保所有的值是通过批处理作业的一个实例。然而,值处理的一个实例的数量依赖于分布列值(即可能存在大量的位置在0000 - 0999范围内,和一些范围在1000 - 1999年)。在这个选项下,数据范围应该设计时考虑到分区。

Under both options, the optimal even distribution of records to batch instances cannot be realized. There is no dynamic configuration of the number of batch instances used.

在两个选项下,最佳均匀分布的记录无法实现批处理实例。没有动态配置使用批处理实例的数量。


*5. Breakup by Views*

*5。分手的观点*

This approach is basically breakup by a key column, but on the database level. It involves breaking up the recordset into views. These views will be used by each instance of the batch application during its processing. The breakup will be done by grouping the data.

这种方法基本上是由键列分手,但在数据库级。它涉及的记录集分解成视图。这些视图将使用批处理应用程序的每个实例在其处理。分手将通过分组数据。

With this option, each instance of a batch application will have to be configured to hit a particular view (instead of the master table). Also, with the addition of new data values, this new group of data will have to be included into a view. There is no dynamic configuration capability, as a change in the number of instances will result in a change to the views.

这个选项,每个实例的批处理应用程序必须配置为一个特定的视图(而非主表)。通过添加新的数据值,这个新组的数据必须包括一个视图。没有动态配置功能,作为一个实例的数量的变化将导致改变的观点。


*6. Addition of a Processing Indicator*

* 6。添加处理指标*

This involves the addition of a new column to the input table, which acts as an indicator. As a preprocessing step, all indicators would be marked to non-processed. During the record fetch stage of the batch application, records are read on the condition that that record is marked non-processed, and once they are read (with lock), they are marked processing. When that record is completed, the indicator is updated to either complete or error. Many instances of a batch application can be started without a change, as the additional column ensures that a record is only processed once.

这涉及到输入表添加一个新列,它充当一个指标。预处理步骤,所有指标将标志着孩子。批处理应用程序的记录获取阶段期间,记录阅读的条件,记录是未经加工的,一旦他们阅读(带锁),它们标志着处理。当记录完成后,更新指标完成或错误。许多批处理应用程序的实例可以开始不改变,作为附加列确保纪录只处理一次。

With this option, I/O on the table increases dynamically. In the case of an updating batch application, this impact is reduced, as a write will have to occur anyway.


使用该选项时,I / O在桌子上动态地增加。一批更新的应用程序中,这种影响降低,作为一个写必须发生。


*7. Extract Table to a Flat File*

* 7。提取表平面文件*

This involves the extraction of the table into a file. This file can then be split into multiple segments and used as input to the batch instances.

这包括表的提取到一个文件中。这个文件可以被分成多个部分,用作输入批处理实例。

With this option, the additional overhead of extracting the table into a file, and splitting it, may cancel out the effect of multi-partitioning. Dynamic configuration can be achieved via changing the file splitting script.


这个选项,额外开销的提取到一个文件中,并分裂,可能抵消multi-partitioning的效果。动态配置可以通过改变文件分割脚本实现。


*8. Use of a Hashing Column*

* 8。使用散列列*

This scheme involves the addition of a hash column (key/index) to the database tables used to retrieve the driver record. This hash column will have an indicator to determine which instance of the batch application will process this particular row. For example, if there are three batch instances to be started, then an indicator of 'A' will mark that row for processing by instance 1, an indicator of 'B' will mark that row for processing by instance 2, etc.

这个计划包括增加一个散列列(键/索引)用于检索的数据库表司机记录。这个散列列将批处理应用程序的一个指标来确定哪些实例将处理这个特定的行。例如,如果有三个批处理启动实例,那么“A”的指标将马克1行处理的实例,“B”的指标将2行处理的实例,等等。

The procedure used to retrieve the records would then have an additional WHERE clause to select all rows marked by a particular indicator. The inserts in this table would involve the addition of the marker field, which would be defaulted to one of the instances (e.g. 'A').

过程用于检索记录将有一个额外的WHERE子句来选择所有行以一个特定的指标。这个表的插入需要附加的标记,这将是违约的一个实例(例如“一个”)。

A simple batch application would be used to update the indicators such as to redistribute the load between the different instances. When a sufficiently large number of new rows have been added, this batch can be run (anytime, except in the batch window) to redistribute the new rows to other instances.

一个简单的批处理应用程序将用来更新指标等不同实例之间的重新分配负载。当一个足够大量的添加新行,这批可以运行(在任何时间,在批处理窗口除外)重新分配其他实例的新行。

Additional instances of the batch application only require the running of the batch application as above to redistribute the indicators to cater for a new number of instances.

批处理应用程序的其他实例只需要上面运行批处理应用程序的重新分配数量的指标,以满足新的实例。


** 4.2数据库和应用程序设计原则 **

如果一个支持多分区(multi-partitioned)的应用程序架构,基于数据库采用主键列(key column)分片方法拆成的多个表,则应该包含一个中心分区仓库来存储分区参数。这种方式提供了灵活性,并保证了可维护性。这个中心仓库通常只由单个表组成,叫做分区表。


存储在分区表中的信息应该是是静态的,并且只能由DBA维护。每个多分区程序对应的单个分区有一行记录,组成这个表。这个表应该包含这些列: 程序ID编号,分区编号(分区的逻辑ID),一个分区对应的主键列（keycolumn）的最小值,分区对应的主键列的最大值.


在程序启动时,应用程序架构(Control Processing Tasklet,控制处理微线程)应该将程序id和分区号传递给该程序。这些变量被用于读取分区表,来确定应用程序应该处理的数据范围(如果使用主键列的话)。另外分区号必须在整个处理过程中用来:

- 为了使合并程序正常工作,需要将分区号添加到输出文件/数据库更新
- 向框架的错误处理程序报告正常处理批处理日志和执行期间发生的所有错误


** 4.3 尽可能杜绝死锁**


当程序并行或分区运行时,会导致数据库资源的争用,还可能会发生死锁(Deadlocks)。其中的关键是数据库设计团队在进行数据库设计时必须考虑尽可能消除潜在的竞争情况。

还要确保设计数据库表的索引时考虑到性能以及死锁预防。

死锁或热点往往发生在管理或架构表上,如日志表、控制表, 锁表(lock tables)。这些影响也应该纳入考虑。为了确定架构可能的瓶颈,一个真实的压力测试是至关重要的。


要最小化数据冲突的影响,架构应该提供一些服务,如附加到数据库或遇到死锁时的 等待-重试(wait-and-retry)间隔时间。这意味着要有一个内置的机制来处理数据库返回码,而不是立即引发错误处理,需要等待一个预定的时间并重试执行数据库操作。


** 4.4参数传递和校验 ** 


对程序开发人员来说,分区架构应该相对透明。框架以分区模式运行时应该执行的相关任务包括:

- 在程序启动之前获取分区参数
- 在程序启动之前验证分区参数
- 在启动时将参数传递给应用程序


验证(validation)要包含必要的检查,以确保:

- 应用程序已经足够涵盖整个数据的分区
- 在各个分片之间没有遗漏断代(gaps)

如果数据库是分片的,可能需要一些额外的验证来保证单个分片不会跨越数据库的片区。


体系架构应该考虑整合分区(partitions)。包括以下关键问题:

- 在进入下一个工作步骤之前是否所有的分区都必须完成?
- 如果一个分区中止了要怎么处理?