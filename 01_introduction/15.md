# 批处理策略

为了辅助批处理系统的设计和实现、应该通过结构示意图和代码实例的形式为设计师和程序员提供基础的批处理程序构建模块和以及处理模式。
在设计批处理Job时,应该将业务逻辑分解成一系列的步骤,使每个步骤都可以利用以下的标准构建模块来实现:


- 转换程序(Conversion Applications): 由外部系统提供或需要写入到外部系统的各种类型的文件,我们都需要为其创建一个转换程序, 用来将所提供的事务记录转换成符合要求的标准格式。这种类型的批处理程序可以部分或全部由转换工具模块组成(translation utility modules)(参见 Basic Batch Services,基本批处理服务)。
- 验证程序(Validation Applications): 验证程序确保所有输入/输出记录都是正确和一致的。验证通常基于文件头和结尾信息, 校验和(checksums)以及记录级别的交叉验证算法。
- 提取程序(Extract Applications): 这种程序从数据库或输入文件读取一堆记录,根据预定义的规则选取记录,并将选取的记录写入到输出文件。
- 提取/更新程序(Extract/Update Applications): 这种程序从数据库或输入文件读取记录,并将输入的每条记录都更新到数据库,或记录到输出文件。
- 处理和更新程序(Processing and Updating Applications): 这种程序对从 提取或验证程序 传过来的输入事务记录进行处理。这些处理通常包括 从数据库读取数据,有可能更新数据库,并创建输出记录。
- 输出/格式化程序(Output/Format Applications): 这种程序从输入文件中读取信息,将数据重组成为标准格式,并打印到输出文件,或者传输给另一个程序或系统。

# !!!下面的内容需要整理

Additionally a basic application shell should be provided for business logic that cannot be built using the previously mentioned building blocks.

还需要有一个额外的程序,上面提到的基本应用程序壳应提供对业务逻辑,不能使用前面提到的构建块。

In addition to the main building blocks, each application may use one or more of standard utility steps, such as:

除了主要构建块,每个应用程序可以使用一个或多个标准的实用程序的步骤,如:

- Sort A Program that reads an input file and produces an output file where records have been re-sequenced according to a sort key field in the records. Sorts are usually performed by standard system utilities.
- Split A program that reads a single input file, and writes each record to one of several output files based on a field value. Splits can be tailored or performed by parameter-driven standard system utilities.
- Merge A program that reads records from multiple input files and produces one output file with combined data from the input files. Merges can be tailored or performed by parameter-driven standard system utilities.

- 排序的程序读取一个输入文件并生成一个输出文件,记录re-sequenced根据某种关键字段的记录。通常由标准系统实用程序。
- 分割一个程序读取一个输入文件,并将每个记录写入输出文件之一基于一个字段值。分歧可以定制或由parameter-driven标准系统实用程序。
- 合并一段程序,其读取记录从多个输入文件并生成一个输出文件,结合数据从输入文件。合并可以定制或由parameter-driven标准系统实用程序。

Batch applications can additionally be categorized by their input source:

批处理应用程序另外可以分类的输入源:

- Database-driven applications are driven by rows or values retrieved from the database.
- File-driven applications are driven by records or values retrieved from a file.
- Message-driven applications are driven by messages retrieved from a message queue.

- 数据库驱动的应用程序是由行或从数据库中检索值。
- File-driven应用程序是由记录或从文件中检索值。
- 消息驱动的应用程序是由从消息队列检索消息。

The foundation of any batch system is the processing strategy. Factors affecting the selection of the strategy include: estimated batch system volume, concurrency with on-line or with another batch systems, available batch windows (and with more enterprises wanting to be up and running 24x7, this leaves no obvious batch windows).

任何批处理系统的处理策略的基础。影响因素的选择策略包括:估计批处理系统卷,并发在线或与另一个批处理系统,可用的批处理窗口(和更多的企业想要全天候运转,这使得没有明显的批处理窗口)。

Typical processing options for batch are:

典型的批处理选项是:

- Normal processing in a batch window during off-line
- Concurrent batch / on-line processing
- Parallel processing of many different batch runs or jobs at the same time
- Partitioning (i.e. processing of many instances of the same job at the same time)
- A combination of these

- 正常处理在离线批处理窗口
- 在线并发批处理/处理
- 并行处理许多不同的批处理运行或工作在同一时间
- 分区(即处理的许多实例相同的工作在同一时间)
- 这些的组合

The order in the list above reflects the implementation complexity, processing in a batch window being the easiest and partitioning the most complex to implement.

上面列表中的顺序反映了实现复杂性,处理在一个批处理窗口的最简单和最复杂的分区实现。

Some or all of these options may be supported by a commercial scheduler.

一些或所有这些选项可能支持的商业调度器。

In the following section these processing options are discussed in more detail. It is important to notice that the commit and locking strategy adopted by batch processes will be dependent on the type of processing performed, and as a rule of thumb and the on-line locking strategy should also use the same principles. Therefore, the batch architecture cannot be simply an afterthought when designing an overall architecture.

在下一节中详细讨论这些处理选项。重要的是要注意,提交和锁定策略采用间歇过程将依赖于类型的处理,作为一个经验法则和在线锁定策略还应该使用相同的原则。因此,批处理架构设计整体架构时不能简单地想了想。

The locking strategy can use only normal database locks, or an additional custom locking service can be implemented in the architecture. The locking service would track database locking (for example by storing the necessary information in a dedicated db-table) and give or deny permissions to the application programs requesting a db operation. Retry logic could also be implemented by this architecture to avoid aborting a batch job in case of a lock situation.


锁定策略只能使用普通数据库锁,或附加自定义锁服务架构可以实现。锁定服务跟踪数据库锁定(例如通过将必要的信息存储在一个专用的db-table),给应用程序请求或拒绝权限数据库操作。重试逻辑也可以实现这种架构,以避免流产的批处理作业,以防锁的情况。


**1. Normal processing in a batch window** For simple batch processes running in a separate batch window, where the data being updated is not required by on-line users or other batch processes, concurrency is not an issue and a single commit can be done at the end of the batch run.

** 1。正常处理在一个批处理窗口** 简单批处理运行在一个单独的批处理窗口,数据不需要更新在线用户或其他批处理,并发性并不是一个问题和一个承诺可以做到年底的批处理运行。

In most cases a more robust approach is more appropriate. A thing to keep in mind is that batch systems have a tendency to grow as time goes by, both in terms of complexity and the data volumes they will handle. If no locking strategy is in place and the system still relies on a single commit point, modifying the batch programs can be painful. Therefore, even with the simplest batch systems, consider the need for commit logic for restart-recovery options as well as the information concerning the more complex cases below.


在大多数情况下,一种更健壮的方法更合适。要记住的一件事是,批处理系统倾向于随着时间的流逝,成长的复杂性和他们处理的数据量。如果没有到位,系统锁定策略仍然依赖于一个单一的点提交,修改批处理程序可以是痛苦的。因此,即使最简单的批处理系统,考虑需要提交restart-recovery逻辑选项以及下面的信息涉及更复杂的情况下。


**2. Concurrent batch / on-line processing ** Batch applications processing data that can simultaneously be updated by on-line users, should not lock any data (either in the database or in files) which could be required by on-line users for more than a few seconds. Also updates should be committed to the database at the end of every few transaction. This minimizes the portion of data that is unavailable to other processes and the elapsed time the data is unavailable.

** 2.并发批处理/在线处理 ** 批处理应用程序处理的数据可以同时更新在线用户,不应该锁定任何数据(数据库或文件)可能需要通过在线用户超过几秒钟。还应提交到数据库更新结束时每隔几个事务。这减少了部分数据,不可用其他进程和时间数据不可用。

Another option to minimize physical locking is to have a logical row-level locking implemented using either an Optimistic Locking Pattern or a Pessimistic Locking Pattern.

减少物理锁的另一个选择是实现一个逻辑行级别锁定使用乐观锁定模式或悲观锁定模式。


- Optimistic locking assumes a low likelihood of record contention. It typically means inserting a timestamp column in each database table used concurrently by both batch and on-line processing. When an application fetches a row for processing, it also fetches the timestamp. As the application then tries to update the processed row, the update uses the original timestamp in the WHERE clause. If the timestamp matches, the data and the timestamp will be updated successfully. If the timestamp does not match, this indicates that another application has updated the same row between the fetch and the update attempt and therefore the update cannot be performed.
- Pessimistic locking is any locking strategy that assumes there is a high likelihood of record contention and therefore either a physical or logical lock needs to be obtained at retrieval time. One type of pessimistic logical locking uses a dedicated lock-column in the database table. When an application retrieves the row for update, it sets a flag in the lock column. With the flag in place, other applications attempting to retrieve the same row will logically fail. When the application that set the flag updates the row, it also clears the flag, enabling the row to be retrieved by other applications. Please note, that the integrity of data must be maintained also between the initial fetch and the setting of the flag, for example by using db locks (e.g., SELECT FOR UPDATE). Note also that this method suffers from the same downside as physical locking except that it is somewhat easier to manage building a time-out mechanism that will get the lock released if the user goes to lunch while the record is locked.

- 乐观锁定假设低记录争用的可能性。这通常意味着每个数据库表中插入一个时间戳列使用并发批处理和在线处理。当一个应用程序读取一行进行处理,同时也获取时间戳。作为应用程序然后尝试更新处理,更新使用原来的时间戳在WHERE子句中。如果时间戳相匹配,数据和时间戳将更新成功。如果时间戳不匹配,这表明,另一个应用程序更新获取和更新之间的同一行,因此不能执行更新。

- 悲观锁定任何假设的锁定策略记录争用的可能性很高,因此需要获得一个物理或逻辑锁在检索时间。一种悲观逻辑锁定使用一个专用lock-column在数据库表中。当应用程序检索更新的行,它设置了一个标记,在锁柱。国旗的地方,其他应用程序试图检索同一行将逻辑上失败。当应用程序设置标志更新行,它也扫清了国旗,使检索行由其他应用程序。请注意,必须维护数据的完整性也初步获取和设置的标志,例如通过使用db锁(例如,选择更新)。还请注意,此方法都有相同的缺点作为物理锁,除了它有点容易管理构建一个超时机制,将锁释放如果用户去午餐,记录被锁定。


These patterns are not necessarily suitable for batch processing, but they might be used for concurrent batch and on-line processing (e.g. in cases where the database doesn't support row-level locking). As a general rule, optimistic locking is more suitable for on-line applications, while pessimistic locking is more suitable for batch applications. Whenever logical locking is used, the same scheme must be used for all applications accessing data entities protected by logical locks.

这些模式并不一定适用于批处理,但他们可能会被用于并发批处理和在线处理的情况下(例如,数据库不支持行级锁定)。作为一般规则,乐观锁定更适合在线应用程序,而悲观锁定更适合批处理应用程序。每当使用逻辑锁定,同样的方案必须用于所有应用程序访问数据实体保护逻辑锁。

Note that both of these solutions only address locking a single record. Often we may need to lock a logically related group of records. With physical locks, you have to manage these very carefully in order to avoid potential deadlocks. With logical locks, it is usually best to build a logical lock manager that understands the logical record groups you want to protect and can ensure that locks are coherent and non-deadlocking. This logical lock manager usually uses its own tables for lock management, contention reporting, time-out mechanism, etc.

请注意,这两个解决方案只有地址锁定单个记录。我们经常需要锁定一组逻辑相关的记录。与物理锁,你必须非常仔细地管理这些为了避免潜在的死锁。与逻辑锁,它通常是最好建立一个理解的逻辑锁管理器逻辑记录组你想保护,可以确保连贯和non-deadlocking锁。这种逻辑锁管理器通常使用自己的表锁管理、争用报告、超时机制,等等。


**3. Parallel Processing** Parallel processing allows multiple batch runs / jobs to run in parallel to minimize the total elapsed batch processing time. This is not a problem as long as the jobs are not sharing the same files, db-tables or index spaces. If they do, this service should be implemented using partitioned data. Another option is to build an architecture module for maintaining interdependencies using a control table. A control table should contain a row for each shared resource and whether it is in use by an application or not. The batch architecture or the application in a parallel job would then retrieve information from that table to determine if it can get access to the resource it needs or not.

** 3。并行处理** 并行处理允许多个批处理运行/工作并行运行批处理总运行时间降到最低。这并不是一个问题,只要工作不共享相同的文件,db-tables或索引空间。如果他们这样做,这个服务应该使用分区数据实现的。另一个选择是构建一个架构模块使用控制表维护相互依赖关系。连续控制表应该包含为每个共享资源和是否在使用一个应用程序。批处理架构或应用程序在并行作业将检索信息的表,以确定是否可以获得所需的资源。

If the data access is not a problem, parallel processing can be implemented through the use of additional threads to process in parallel. In the mainframe environment, parallel job classes have traditionally been used, in order to ensure adequate CPU time for all the processes. Regardless, the solution has to be robust enough to ensure time slices for all the running processes.

如果数据访问并不是一个问题,并行处理可以实现通过使用额外的线程并行处理。在大型机环境中,并行作业类传统上被使用,以确保足够的CPU时间的进程。无论如何,解决方案必须足够强劲,能够确保所有正在运行的进程的时间片。

Other key issues in parallel processing include load balancing and the availability of general system resources such as files, database buffer pools etc. Also note that the control table itself can easily become a critical resource.

其他关键问题并行处理包括负载平衡和一般的可用性系统资源(如文件、数据库缓冲池等。还要注意控制表本身可以很容易地成为一个至关重要的资源。


**4. Partitioning** Using partitioning allows multiple versions of large batch applications to run concurrently. The purpose of this is to reduce the elapsed time required to process long batch jobs. Processes which can be successfully partitioned are those where the input file can be split and/or the main database tables partitioned to allow the application to run against different sets of data.

** 4。分片**使用分区允许多个版本的批处理应用程序并发地运行。这样做的目的是减少过程所需的时间长的批处理作业。流程可以成功分区是那些输入文件可以分裂和/或主要数据库表分区允许应用程序运行在不同的数据。

In addition, processes which are partitioned must be designed to only process their assigned data set. A partitioning architecture has to be closely tied to the database design and the database partitioning strategy. Please note, that the database partitioning doesn't necessarily mean physical partitioning of the database, although in most cases this is advisable. The following picture illustrates the partitioning approach:

此外,过程只分区必须设计过程的分配数据集。一个分区结构是密切相关的数据库设计和数据库分区策略。请注意,数据库分区并不一定意味着物理分区的数据库,尽管在大多数情况下这是明智的。下面的图片展示了分区的方法:

The architecture should be flexible enough to allow dynamic configuration of the number of partitions. Both automatic and user controlled configuration should be considered. Automatic configuration may be based on parameters such as the input file size and/or the number of input records.

体系结构应该足够灵活,允许动态配置分区的数量。自动控制和用户配置应考虑。自动配置等参数可能是基于输入文件大小和/或输入记录的数量。


**4.1 Partitioning Approaches** The following lists some of the possible partitioning approaches. Selecting a partitioning approach has to be done on a case-by-case basis.

** 4.1分区方法 ** 下面列出了一些可能的分区方法。选择一个分区方法要根据具体情况来完成。


*1. Fixed and Even Break-Up of Record Set*

* 1。固定的记录集甚至解体 *

This involves breaking the input record set into an even number of portions (e.g. 10, where each portion will have exactly 1/10th of the entire record set). Each portion is then processed by one instance of the batch/extract application.

这涉及到打破纪录输入偶数的部分(例如10,每个部分都有完全的整个记录集)。每个部分由一个处理批处理/提取应用程序的实例。

In order to use this approach, preprocessing will be required to split the recordset up. The result of this split will be a lower and upper bound placement number which can be used as input to the batch/extract application in order to restrict its processing to its portion alone.

为了使用这种方法,预处理需要将记录集。分裂的结果将是一个最大值和最小位置数值,可以用作输入批处理/提取应用程序为了限制其处理部分。

Preprocessing could be a large overhead as it has to calculate and determine the bounds of each portion of the record set.

预处理可能是一个巨大的开销,因为它必须计算确定的每个部分的记录集。


*2. Breakup by a Key Column*

* 2。键列分手 *

This involves breaking up the input record set by a key column such as a location code, and assigning data from each key to a batch instance. In order to achieve this, column values can either be

这涉及到分手的输入记录键列如位置代码,从每个关键和分配数据批处理实例。为了达到这个目标,可以是列值

*3. Assigned to a batch instance via a partitioning table (see below for details).*

* 3。分配给一个批处理实例通过分区表(详情见下文)。*

*4. Assigned to a batch instance by a portion of the value (e.g. values 0000-0999, 1000 - 1999, etc.)*

* 4。部分分配给一个批处理实例的值(例如值0000 - 0999、1000 - 1999、等等)*



Under option 1, addition of new values will mean a manual reconfiguration of the batch/extract to ensure that the new value is added to a particular instance.

根据选项1,添加新值将意味着手工重新配置批/提取,以确保新的值被添加到一个特定的实例。

Under option 2, this will ensure that all values are covered via an instance of the batch job. However, the number of values processed by one instance is dependent on the distribution of column values (i.e. there may be a large number of locations in the 0000-0999 range, and few in the 1000-1999 range). Under this option, the data range should be designed with partitioning in mind.

选项2下,这将确保所有的值是通过批处理作业的一个实例。然而,值处理的一个实例的数量依赖于分布列值(即可能存在大量的位置在0000 - 0999范围内,和一些范围在1000 - 1999年)。在这个选项下,数据范围应该设计时考虑到分区。

Under both options, the optimal even distribution of records to batch instances cannot be realized. There is no dynamic configuration of the number of batch instances used.

在两个选项下,最佳均匀分布的记录无法实现批处理实例。没有动态配置使用批处理实例的数量。


*5. Breakup by Views*

*5。分手的观点*

This approach is basically breakup by a key column, but on the database level. It involves breaking up the recordset into views. These views will be used by each instance of the batch application during its processing. The breakup will be done by grouping the data.

这种方法基本上是由键列分手,但在数据库级。它涉及的记录集分解成视图。这些视图将使用批处理应用程序的每个实例在其处理。分手将通过分组数据。

With this option, each instance of a batch application will have to be configured to hit a particular view (instead of the master table). Also, with the addition of new data values, this new group of data will have to be included into a view. There is no dynamic configuration capability, as a change in the number of instances will result in a change to the views.

这个选项,每个实例的批处理应用程序必须配置为一个特定的视图(而非主表)。通过添加新的数据值,这个新组的数据必须包括一个视图。没有动态配置功能,作为一个实例的数量的变化将导致改变的观点。


*6. Addition of a Processing Indicator*

* 6。添加处理指标*

This involves the addition of a new column to the input table, which acts as an indicator. As a preprocessing step, all indicators would be marked to non-processed. During the record fetch stage of the batch application, records are read on the condition that that record is marked non-processed, and once they are read (with lock), they are marked processing. When that record is completed, the indicator is updated to either complete or error. Many instances of a batch application can be started without a change, as the additional column ensures that a record is only processed once.

这涉及到输入表添加一个新列,它充当一个指标。预处理步骤,所有指标将标志着孩子。批处理应用程序的记录获取阶段期间,记录阅读的条件,记录是未经加工的,一旦他们阅读(带锁),它们标志着处理。当记录完成后,更新指标完成或错误。许多批处理应用程序的实例可以开始不改变,作为附加列确保纪录只处理一次。

With this option, I/O on the table increases dynamically. In the case of an updating batch application, this impact is reduced, as a write will have to occur anyway.


使用该选项时,I / O在桌子上动态地增加。一批更新的应用程序中,这种影响降低,作为一个写必须发生。


*7. Extract Table to a Flat File*

* 7。提取表平面文件*

This involves the extraction of the table into a file. This file can then be split into multiple segments and used as input to the batch instances.

这包括表的提取到一个文件中。这个文件可以被分成多个部分,用作输入批处理实例。

With this option, the additional overhead of extracting the table into a file, and splitting it, may cancel out the effect of multi-partitioning. Dynamic configuration can be achieved via changing the file splitting script.


这个选项,额外开销的提取到一个文件中,并分裂,可能抵消multi-partitioning的效果。动态配置可以通过改变文件分割脚本实现。


*8. Use of a Hashing Column*

* 8。使用散列列*

This scheme involves the addition of a hash column (key/index) to the database tables used to retrieve the driver record. This hash column will have an indicator to determine which instance of the batch application will process this particular row. For example, if there are three batch instances to be started, then an indicator of 'A' will mark that row for processing by instance 1, an indicator of 'B' will mark that row for processing by instance 2, etc.

这个计划包括增加一个散列列(键/索引)用于检索的数据库表司机记录。这个散列列将批处理应用程序的一个指标来确定哪些实例将处理这个特定的行。例如,如果有三个批处理启动实例,那么“A”的指标将马克1行处理的实例,“B”的指标将2行处理的实例,等等。

The procedure used to retrieve the records would then have an additional WHERE clause to select all rows marked by a particular indicator. The inserts in this table would involve the addition of the marker field, which would be defaulted to one of the instances (e.g. 'A').

过程用于检索记录将有一个额外的WHERE子句来选择所有行以一个特定的指标。这个表的插入需要附加的标记,这将是违约的一个实例(例如“一个”)。

A simple batch application would be used to update the indicators such as to redistribute the load between the different instances. When a sufficiently large number of new rows have been added, this batch can be run (anytime, except in the batch window) to redistribute the new rows to other instances.

一个简单的批处理应用程序将用来更新指标等不同实例之间的重新分配负载。当一个足够大量的添加新行,这批可以运行(在任何时间,在批处理窗口除外)重新分配其他实例的新行。

Additional instances of the batch application only require the running of the batch application as above to redistribute the indicators to cater for a new number of instances.

批处理应用程序的其他实例只需要上面运行批处理应用程序的重新分配数量的指标,以满足新的实例。



**4.2 Database and Application design Principles**

** 4.2数据库和应用程序设计原则 **

An architecture that supports multi-partitioned applications which run against partitioned database tables using the key column approach, should include a central partition repository for storing partition parameters. This provides flexibility and ensures maintainability. The repository will generally consist of a single table known as the partition table.

一个架构,支持多分区运行的应用程序使用密钥对分区数据库表列的方法,应该包括一个中央分区存储库用于存储分区参数。这提供了灵活性,确保可维护性。存储库通常包含一个表称为分区表。

Information stored in the partition table will be static and in general should be maintained by the DBA. The table should consist of one row of information for each partition of a multi-partitioned application. The table should have columns for: Program ID Code, Partition Number (Logical ID of the partition), Low Value of the db key column for this partition, High Value of the db key column for this partition.

信息存储在分区表将是静态的,一般应由DBA。一行的表应该包含的信息为每个分区的多分区的应用程序。表应该列:程序ID代码,分区号(逻辑分区的ID),低价值的db为这个分区键列,高价值的db为这个分区键列。

On program start-up the program id and partition number should be passed to the application from the architecture (Control Processing Tasklet). These variables are used to read the partition table, to determine what range of data the application is to process (if a key column approach is used). In addition the partition number must be used throughout the processing to:


在程序启动的程序id和分区号应该传递给应用程序的架构(控制处理微线程)。这些变量是用于读取分区表,来确定范围的数据处理应用程序(如果使用键列的方法)。另外的分区号必须使用整个处理:


- Add to the output files/database updates in order for the merge process to work properly
- Report normal processing to the batch log and any errors that occur during execution to the architecture error handler
- 添加到输出文件/数据库更新为了合并进程正常工作
- 报告正常处理批处理日志和执行期间发生的任何错误的错误处理程序架构

**4.3 Minimizing Deadlocks**

** 4.3减少死锁**

When applications run in parallel or partitioned, contention in database resources and deadlocks may occur. It is critical that the database design team eliminates potential contention situations as far as possible as part of the database design.

当应用程序运行在并行或分区,在数据库资源争用,可能发生死锁。关键是数据库设计团队尽可能消除潜在的争用情况作为数据库设计的一部分。


Also ensure that the database index tables are designed with deadlock prevention and performance in mind.

也确保数据库索引表设计时考虑到死锁预防和性能。

Deadlocks or hot spots often occur in administration or architecture tables such as log tables, control tables, and lock tables. The implications of these should be taken into account as well. A realistic stress test is crucial for identifying the possible bottlenecks in the architecture.

死锁或热点往往发生在政府或架构表如日志表、控制表,锁表。这些应该考虑的影响。一个现实的压力测试是至关重要的架构确定可能的瓶颈。


To minimize the impact of conflicts on data, the architecture should provide services such as wait-and-retry intervals when attaching to a database or when encountering a deadlock. This means a built-in mechanism to react to certain database return codes and instead of issuing an immediate error handling, waiting a predetermined amount of time and retrying the database operation.


最小化数据冲突的影响,体系结构应该提供服务,如wait-and-retry间隔时附加到数据库或遇到死锁。这意味着一个内置的机制来应对某些数据库返回的代码,而不是发行立即错误处理,等待一个预定的时间和重试数据库操作。


**4.4 Parameter Passing and Validation**

** 4.4参数传递和验证 ** 

The partition architecture should be relatively transparent to application developers. The architecture should perform all tasks associated with running the application in a partitioned mode including:


分区架构应该相对透明的给应用程序开发人员。相关的架构应该执行所有任务运行应用程序在分区模式包括:


- Retrieve partition parameters before application start-up
- Validate partition parameters before application start-up
- Pass parameters to application at start-up
- 检索应用程序启动之前分区参数
- 验证应用程序启动之前分区参数
- 将参数传递给应用程序在启动



The validation should include checks to ensure that:

验证应包括检查,以确保:

- the application has sufficient partitions to cover the whole data range
- there are no gaps between partitions
- 应用程序已经足够涵盖整个数据的分区
- 在分区之间没有差距

If the database is partitioned, some additional validation may be necessary to ensure that a single partition does not span database partitions.


如果数据库是分区的,可能需要一些额外的验证确保单个分区不会跨数据库分区。

Also the architecture should take into consideration the consolidation of partitions. Key questions include:

的体系结构应该考虑整合分区。关键问题包括:

- Must all the partitions be finished before going into the next job step?
- What happens if one of the partitions aborts?
- 所有的分区必须在进入下一个工作步骤之前完成吗?
- 如果一个分区中止?