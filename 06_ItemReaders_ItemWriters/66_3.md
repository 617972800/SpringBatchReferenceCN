## 6.6.3 FlatFileItemWriter ##

Writing out to flat files has the same problems and issues that reading in from a file must overcome. A step must be able to write out in either delimited or fixed length formats in a transactional manner.

**LineAggregator**

Just as the LineTokenizer interface is necessary to take an item and turn it into a String, file writing must have a way to aggregate multiple fields into a single string for writing to a file. In Spring Batch this is the LineAggregator:

	public interface LineAggregator<T> {
	
	    public String aggregate(T item);
	
	}

The LineAggregator is the opposite of a LineTokenizer. LineTokenizer takes a String and returns a FieldSet, whereas LineAggregator takes an item and returns a String.

**PassThroughLineAggregator**

The most basic implementation of the LineAggregator interface is the PassThroughLineAggregator, which simply assumes that the object is already a string, or that its string representation is acceptable for writing:

	public class PassThroughLineAggregator<T> implements LineAggregator<T> {
	
	    public String aggregate(T item) {
	        return item.toString();
	    }
	}

The above implementation is useful if direct control of creating the string is required, but the advantages of a FlatFileItemWriter, such as transaction and restart support, are necessary.

**Simplified File Writing Example**

Now that the LineAggregator interface and its most basic implementation, PassThroughLineAggregator, have been defined, the basic flow of writing can be explained:

1. The object to be written is passed to the LineAggregator in order to obtain a String.
1. The returned String is written to the configured file.

The following excerpt from the FlatFileItemWriter expresses this in code:

	public void write(T item) throws Exception {
	    write(lineAggregator.aggregate(item) + LINE_SEPARATOR);
	}



A simple configuration would look like the following:

	<bean id="itemWriter" class="org.spr...FlatFileItemWriter">
	    <property name="resource" value="file:target/test-outputs/output.txt" />
	    <property name="lineAggregator">
	        <bean class="org.spr...PassThroughLineAggregator"/>
	    </property>
	</bean>


**FieldExtractor**

The above example may be useful for the most basic uses of a writing to a file. However, most users of the FlatFileItemWriter will have a domain object that needs to be written out, and thus must be converted into a line. In file reading, the following was required:

1. Read one line from the file.
1. Pass the string line into the LineTokenizer#tokenize() method, in order to retrieve a FieldSet
1. Pass the FieldSet returned from tokenizing to a FieldSetMapper, returning the result from the ItemReader#read() method


File writing has similar, but inverse steps:

1. Pass the item to be written to the writer
1. convert the fields on the item into an array
1. aggregate the resulting array into a line


Because there is no way for the framework to know which fields from the object need to be written out, a FieldExtractor must be written to accomplish the task of turning the item into an array:

	public interface FieldExtractor<T> {
	
	    Object[] extract(T item);
	
	}
Implementations of the FieldExtractor interface should create an array from the fields of the provided object, which can then be written out with a delimiter between the elements, or as part of a field-width line.

**PassThroughFieldExtractor**

There are many cases where a collection, such as an array, Collection, or FieldSet, needs to be written out. "Extracting" an array from a one of these collection types is very straightforward: simply convert the collection to an array. Therefore, the PassThroughFieldExtractor should be used in this scenario. It should be noted, that if the object passed in is not a type of collection, then the PassThroughFieldExtractor will return an array containing solely the item to be extracted.

**BeanWrapperFieldExtractor**

As with the BeanWrapperFieldSetMapper described in the file reading section, it is often preferable to configure how to convert a domain object to an object array, rather than writing the conversion yourself. The BeanWrapperFieldExtractor provides just this type of functionality:

	BeanWrapperFieldExtractor<Name> extractor = new BeanWrapperFieldExtractor<Name>();
	extractor.setNames(new String[] { "first", "last", "born" });
	
	String first = "Alan";
	String last = "Turing";
	int born = 1912;
	
	Name n = new Name(first, last, born);
	Object[] values = extractor.extract(n);
	
	assertEquals(first, values[0]);
	assertEquals(last, values[1]);
	assertEquals(born, values[2]);


This extractor implementation has only one required property, the names of the fields to map. Just as the BeanWrapperFieldSetMapper needs field names to map fields on the FieldSet to setters on the provided object, the BeanWrapperFieldExtractor needs names to map to getters for creating an object array. It is worth noting that the order of the names determines the order of the fields within the array.

**Delimited File Writing Example**

The most basic flat file format is one in which all fields are separated by a delimiter. This can be accomplished using a DelimitedLineAggregator. The example below writes out a simple domain object that represents a credit to a customer account:

	public class CustomerCredit {
	
	    private int id;
	    private String name;
	    private BigDecimal credit;
	
	    //getters and setters removed for clarity
	}

Because a domain object is being used, an implementation of the FieldExtractor interface must be provided, along with the delimiter to use:

	<bean id="itemWriter" class="org.springframework.batch.item.file.FlatFileItemWriter">
	    <property name="resource" ref="outputResource" />
	    <property name="lineAggregator">
	        <bean class="org.spr...DelimitedLineAggregator">
	            <property name="delimiter" value=","/>
	            <property name="fieldExtractor">
	                <bean class="org.spr...BeanWrapperFieldExtractor">
	                    <property name="names" value="name,credit"/>
	                </bean>
	            </property>
	        </bean>
	    </property>
	</bean>

In this case, the BeanWrapperFieldExtractor described earlier in this chapter is used to turn the name and credit fields within CustomerCredit into an object array, which is then written out with commas between each field.

**Fixed Width File Writing Example**

Delimited is not the only type of flat file format. Many prefer to use a set width for each column to delineate between fields, which is usually referred to as 'fixed width'. Spring Batch supports this in file writing via the FormatterLineAggregator. Using the same CustomerCredit domain object described above, it can be configured as follows:

	<bean id="itemWriter" class="org.springframework.batch.item.file.FlatFileItemWriter">
	    <property name="resource" ref="outputResource" />
	    <property name="lineAggregator">
	        <bean class="org.spr...FormatterLineAggregator">
	            <property name="fieldExtractor">
	                <bean class="org.spr...BeanWrapperFieldExtractor">
	                    <property name="names" value="name,credit" />
	                </bean>
	            </property>
	            <property name="format" value="%-9s%-2.0f" />
	        </bean>
	    </property>
	</bean>


Most of the above example should look familiar. However, the value of the format property is new:
	
	<property name="format" value="%-9s%-2.0f" />


The underlying implementation is built using the same Formatter added as part of Java 5. The Java Formatter is based on the printf functionality of the C programming language. Most details on how to configure a formatter can be found in the javadoc of Formatter.

**Handling File Creation**

FlatFileItemReader has a very simple relationship with file resources. When the reader is initialized, it opens the file if it exists, and throws an exception if it does not. File writing isn't quite so simple. At first glance it seems like a similar straight forward contract should exist for FlatFileItemWriter: if the file already exists, throw an exception, and if it does not, create it and start writing. However, potentially restarting a Job can cause issues. In normal restart scenarios, the contract is reversed: if the file exists, start writing to it from the last known good position, and if it does not, throw an exception. However, what happens if the file name for this job is always the same? In this case, you would want to delete the file if it exists, unless it's a restart. Because of this possibility, the FlatFileItemWriter contains the property, shouldDeleteIfExists. Setting this property to true will cause an existing file with the same name to be deleted when the writer is opened.