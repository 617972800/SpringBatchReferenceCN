## 6.6.2 FlatFileItemReader ##

> **译注**: 
> 
> 本文中 将 Flat File 翻译为“平面文件”, 这是一种没有特殊格式的非二进制的文件，里面的内容没有相对关系结构的记录。


平面文件(flat file)是最多包含二维(表格)数据的任意类型的文件。在 Spring Batch 框架中 **FlatFileItemReader** 类负责读取平面文件, 该类提供了用于读取和解析平面文件的基本功能。FlatFileItemReader 主要依赖两个东西: **Resource** 和 **LineMapper**。LineMapper接口将在下一节详细讨论。 `resource` 属性代表一个 Spring Core Resource(Spring核心资源)。关于如何创建这一类 bean 的文档可以参考 [Spring框架, Chapter 5.Resources](http://docs.spring.io/spring/docs/3.2.x/spring-framework-reference/html/resources.html)。所以本文档就不再深入讲解创建 Resource 对象的细节。 但可以找到一个文件系统资源的简单示例，如下所示:


	Resource resource = new FileSystemResource("resources/trades.csv");

在复杂的批处理环境中，目录结构通常由EAI基础设施管理, 并且会建立放置区(drop zones)，让外部接口将文件从ftp移动到批处理位置, 反之亦然。文件移动工具(File moving utilities)超出了spring batch架构的范畴, 但在批处理作业中包括文件移动步骤这种事情那也是很常见的。 批处理架构只需要知道如何定位需要处理的文件就足够了。Spring Batch 将会从这个起始点开始，将数据传输给数据管道。当然, Spring Integration也提供了很多这一类的服务。


**FlatFileItemReader** 中的其他属性让你可以进一步指定数据如何解析:


**Table 6.1. FlatFileItemReader 的属性(Properties)**



<table summary="FlatFileItemReader Properties" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; ">
	<colgroup>
		<col align="center">
		<col>
		<col>
	</colgroup>
	<thead>
		<tr>
			<th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="center">属性(Property)</th><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="center">类型(Type)</th><th style="border-bottom: 0.5pt solid ; " align="center">说明(Description)</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">comments</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">String[]</td><td style="border-bottom: 0.5pt solid ; " align="left">指定行前缀，用来表明哪些是注释行</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">encoding</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">String</td><td style="border-bottom: 0.5pt solid ; " align="left">指定使用哪种文本编码 -
			默认值为 "ISO-8859-1"</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">lineMapper</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">LineMapper</td><td style="border-bottom: 0.5pt solid ; " align="left">将一个 <code class="classname">
				String</code> 转换为相应的 <code class="classname">
				Object</code>.</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">linesToSkip</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">int</td><td style="border-bottom: 0.5pt solid ; " align="left">在文件顶部有多少行需要跳过/忽略</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">recordSeparatorPolicy</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">RecordSeparatorPolicy</td><td style="border-bottom: 0.5pt solid ; " align="left">记录分拆策略, 用于确定行尾, 以及如果在引号之中时，如何处理跨行的内容.</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">resource</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">Resource</td><td style="border-bottom: 0.5pt solid ; " align="left">从哪个资源读取数据.</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">skippedLinesCallback</td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">LineCallbackHandler</td><td style="border-bottom: 0.5pt solid ; " align="left">忽略输入文件中某些行时, 会将忽略行的原始内容传递给这个回调接口。 如果 <code>linesToSkip</code> 设置为<b>2</b>, 那么这个接口就会被调用<b>2</b>次。
</td>
		</tr>
		<tr>
			<td style="border-right: 0.5pt solid ; " align="left">strict</td><td style="border-right: 0.5pt solid ; " align="left">boolean</td><td style="" align="left">如果处于严格模式(strict mode), reader 在 ExecutionContext 中执行时，如果输入资源不存在, 则抛出异常.</td>
		</tr>
	</tbody>
</table>


<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>

**LineMapper**


就如同 **RowMapper** 在底层根据 ResultSet 构造一个 Object 并返回， 平面文件处理过程中也需要将一行 String 转换并构造成 Object :


	public interface LineMapper<T> {
	
	    T mapLine(String line, int lineNumber) throws Exception;
	
	}


基本的约定是, 给定当前行以及和它关联的行号(line number), mapper 应该能够返回一个领域对象。这类似于在 RowMapper 中每一行也有一个 line number 相关联, 正如 ResultSet 中的每一行(Row)都有其绑定的 row number。这允许行号能被绑定到生成的领域对象以方便比较(identity comparison)或者更方便进行日志记录。

但与 RowMapper 不同的是, LineMapper 只能取得原始行的String值, 正如上面所说, 给你的是一个半成品。 这行文本值必须先被解析为 FieldSet, 然后才可以映射为一个对象,如下所述。


**LineTokenizer**

An abstraction for turning a line of input into a line into a FieldSet is necessary because there can be many formats of flat file data that need to be converted to a FieldSet. In Spring Batch, this interface is the LineTokenizer:

	public interface LineTokenizer {
	
	    FieldSet tokenize(String line);
	
	}

The contract of a LineTokenizer is such that, given a line of input (in theory the String could encompass more than one line), a FieldSet representing the line will be returned. This FieldSet can then be passed to a FieldSetMapper. Spring Batch contains the following LineTokenizer implementations:

- DelmitedLineTokenizer Used for files where fields in a record are separated by a delimiter. The most common delimiter is a comma, but pipes or semicolons are often used as well.
- FixedLengthTokenizer Used for files where fields in a record are each a 'fixed width'. The width of each field must be defined for each record type.
- PatternMatchingCompositeLineTokenizer Determines which among a list of LineTokenizers should be used on a particular line by checking against a pattern.

**FieldSetMapper**

The FieldSetMapper interface defines a single method, mapFieldSet, which takes a FieldSet object and maps its contents to an object. This object may be a custom DTO, a domain object, or a simple array, depending on the needs of the job. The FieldSetMapper is used in conjunction with the LineTokenizer to translate a line of data from a resource into an object of the desired type:

	public interface FieldSetMapper<T> {
	
	    T mapFieldSet(FieldSet fieldSet);
	
	}
The pattern used is the same as the RowMapper used by JdbcTemplate.

**DefaultLineMapper**

Now that the basic interfaces for reading in flat files have been defined, it becomes clear that three basic steps are required:

1. Read one line from the file.
2. Pass the string line into the LineTokenizer#tokenize() method, in order to retrieve a FieldSet.
3. Pass the FieldSet returned from tokenizing to a FieldSetMapper, returning the result from the ItemReader#read() method.

The two interfaces described above represent two separate tasks: converting a line into a FieldSet, and mapping a FieldSet to a domain object. Because the input of a LineTokenizer matches the input of the LineMapper (a line), and the output of a FieldSetMapper matches the output of the LineMapper, a default implementation that uses both a LineTokenizer and FieldSetMapper is provided. The DefaultLineMapper represents the behavior most users will need:

	public class DefaultLineMapper<T> implements LineMapper<T>, InitializingBean {
	
	    private LineTokenizer tokenizer;
	
	    private FieldSetMapper<T> fieldSetMapper;
	
	    public T mapLine(String line, int lineNumber) throws Exception {
	        return fieldSetMapper.mapFieldSet(tokenizer.tokenize(line));
	    }
	
	    public void setLineTokenizer(LineTokenizer tokenizer) {
	        this.tokenizer = tokenizer;
	    }
	
	    public void setFieldSetMapper(FieldSetMapper<T> fieldSetMapper) {
	        this.fieldSetMapper = fieldSetMapper;
	    }
	}


The above functionality is provided in a default implementation, rather than being built into the reader itself (as was done in previous versions of the framework) in order to allow users greater flexibility in controlling the parsing process, especially if access to the raw line is needed.

**Simple Delimited File Reading Example**

The following example will be used to illustrate this using an actual domain scenario. This particular batch job reads in football players from the following file:

	ID,lastName,firstName,position,birthYear,debutYear
	"AbduKa00,Abdul-Jabbar,Karim,rb,1974,1996",
	"AbduRa00,Abdullah,Rabih,rb,1975,1999",
	"AberWa00,Abercrombie,Walter,rb,1959,1982",
	"AbraDa00,Abramowicz,Danny,wr,1945,1967",
	"AdamBo00,Adams,Bob,te,1946,1969",
	"AdamCh00,Adams,Charlie,wr,1979,2003"       
 
The contents of this file will be mapped to the following Player domain object:

	public class Player implements Serializable {
	
	    private String ID;
	    private String lastName;
	    private String firstName;
	    private String position;
	    private int birthYear;
	    private int debutYear;
	
	    public String toString() {
	        return "PLAYER:ID=" + ID + ",Last Name=" + lastName +
	            ",First Name=" + firstName + ",Position=" + position +
	            ",Birth Year=" + birthYear + ",DebutYear=" +
	            debutYear;
	    }
	
	    // setters and getters...
	}


In order to map a FieldSet into a Player object, a FieldSetMapper that returns players needs to be defined:

	protected static class PlayerFieldSetMapper implements FieldSetMapper<Player> {
	    public Player mapFieldSet(FieldSet fieldSet) {
	        Player player = new Player();
	
	        player.setID(fieldSet.readString(0));
	        player.setLastName(fieldSet.readString(1));
	        player.setFirstName(fieldSet.readString(2));
	        player.setPosition(fieldSet.readString(3));
	        player.setBirthYear(fieldSet.readInt(4));
	        player.setDebutYear(fieldSet.readInt(5));
	
	        return player;
	    }
	}


The file can then be read by correctly constructing a FlatFileItemReader and calling read:

	FlatFileItemReader<Player> itemReader = new FlatFileItemReader<Player>();
	itemReader.setResource(new FileSystemResource("resources/players.csv"));
	//DelimitedLineTokenizer defaults to comma as its delimiter
	LineMapper<Player> lineMapper = new DefaultLineMapper<Player>();
	lineMapper.setLineTokenizer(new DelimitedLineTokenizer());
	lineMapper.setFieldSetMapper(new PlayerFieldSetMapper());
	itemReader.setLineMapper(lineMapper);
	itemReader.open(new ExecutionContext());
	Player player = itemReader.read();


Each call to read will return a new Player object from each line in the file. When the end of the file is reached, null will be returned.

**Mapping Fields by Name**

There is one additional piece of functionality that is allowed by both DelimitedLineTokenizer and FixedLengthTokenizer that is similar in function to a Jdbc ResultSet. The names of the fields can be injected into either of these LineTokenizer implementations to increase the readability of the mapping function. First, the column names of all fields in the flat file are injected into the tokenizer:

	tokenizer.setNames(new String[] {"ID", "lastName","firstName","position","birthYear","debutYear"});          

A FieldSetMapper can use this information as follows:

	public class PlayerMapper implements FieldSetMapper<Player> {
	    public Player mapFieldSet(FieldSet fs) {
	
	       if(fs == null){
	           return null;
	       }
	
	       Player player = new Player();
	       player.setID(fs.readString("ID"));
	       player.setLastName(fs.readString("lastName"));
	       player.setFirstName(fs.readString("firstName"));
	       player.setPosition(fs.readString("position"));
	       player.setDebutYear(fs.readInt("debutYear"));
	       player.setBirthYear(fs.readInt("birthYear"));
	
	       return player;
	   }
	}


**Automapping FieldSets to Domain Objects**

For many, having to write a specific FieldSetMapper is equally as cumbersome as writing a specific RowMapper for a JdbcTemplate. Spring Batch makes this easier by providing a FieldSetMapper that automatically maps fields by matching a field name with a setter on the object using the JavaBean specification. Again using the football example, the BeanWrapperFieldSetMapper configuration looks like the following:

	<bean id="fieldSetMapper"
	      class="org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper">
	    <property name="prototypeBeanName" value="player" />
	</bean>
	
	<bean id="player"
	      class="org.springframework.batch.sample.domain.Player"
	      scope="prototype" />


For each entry in the FieldSet, the mapper will look for a corresponding setter on a new instance of the Player object (for this reason, prototype scope is required) in the same way the Spring container will look for setters matching a property name. Each available field in the FieldSet will be mapped, and the resultant Player object will be returned, with no code required.

**Fixed Length File Formats**

So far only delimited files have been discussed in much detail, however, they represent only half of the file reading picture. Many organizations that use flat files use fixed length formats. An example fixed length file is below:

	UK21341EAH4121131.11customer1
	UK21341EAH4221232.11customer2
	UK21341EAH4321333.11customer3
	UK21341EAH4421434.11customer4
	UK21341EAH4521535.11customer5

While this looks like one large field, it actually represent 4 distinct fields:

1. ISIN: Unique identifier for the item being order - 12 characters long.
1. Quantity: Number of this item being ordered - 3 characters long.
1. Price: Price of the item - 5 characters long.
1. Customer: Id of the customer ordering the item - 9 characters long.


When configuring the FixedLengthLineTokenizer, each of these lengths must be provided in the form of ranges:

	<bean id="fixedLengthLineTokenizer"
	      class="org.springframework.batch.io.file.transform.FixedLengthTokenizer">
	    <property name="names" value="ISIN,Quantity,Price,Customer" />
	    <property name="columns" value="1-12, 13-15, 16-20, 21-29" />
	</bean>


Because the FixedLengthLineTokenizer uses the same LineTokenizer interface as discussed above, it will return the same FieldSet as if a delimiter had been used. This allows the same approaches to be used in handling its output, such as using the BeanWrapperFieldSetMapper.

**[Note]	Note**
Supporting the above syntax for ranges requires that a specialized property editor, RangeArrayPropertyEditor, be configured in the ApplicationContext. However, this bean is automatically declared in an ApplicationContext where the batch namespace is used.

**Multiple Record Types within a Single File**

All of the file reading examples up to this point have all made a key assumption for simplicity's sake: all of the records in a file have the same format. However, this may not always be the case. It is very common that a file might have records with different formats that need to be tokenized differently and mapped to different objects. The following excerpt from a file illustrates this:

	USER;Smith;Peter;;T;20014539;F
	LINEA;1044391041ABC037.49G201XX1383.12H
	LINEB;2134776319DEF422.99M005LI


In this file we have three types of records, "USER", "LINEA", and "LINEB". A "USER" line corresponds to a User object. "LINEA" and "LINEB" both correspond to Line objects, though a "LINEA" has more information than a "LINEB".

The ItemReader will read each line individually, but we must specify different LineTokenizer and FieldSetMapper objects so that the ItemWriter will receive the correct items. The PatternMatchingCompositeLineMapper makes this easy by allowing maps of patterns to LineTokenizers and patterns to FieldSetMappers to be configured:

	<bean id="orderFileLineMapper"
	      class="org.spr...PatternMatchingCompositeLineMapper">
	    <property name="tokenizers">
	        <map>
	            <entry key="USER*" value-ref="userTokenizer" />
	            <entry key="LINEA*" value-ref="lineATokenizer" />
	            <entry key="LINEB*" value-ref="lineBTokenizer" />
	        </map>
	    </property>
	    <property name="fieldSetMappers">
	        <map>
	            <entry key="USER*" value-ref="userFieldSetMapper" />
	            <entry key="LINE*" value-ref="lineFieldSetMapper" />
	        </map>
	    </property>
	</bean>


In this example, "LINEA" and "LINEB" have separate LineTokenizers but they both use the same FieldSetMapper.

The PatternMatchingCompositeLineMapper makes use of the PatternMatcher's match method in order to select the correct delegate for each line. The PatternMatcher allows for two wildcard characters with special meaning: the question mark ("?") will match exactly one character, while the asterisk ("*") will match zero or more characters. Note that in the configuration above, all patterns end with an asterisk, making them effectively prefixes to lines. The PatternMatcher will always match the most specific pattern possible, regardless of the order in the configuration. So if "LINE*" and "LINEA*" were both listed as patterns, "LINEA" would match pattern "LINEA*", while "LINEB" would match pattern "LINE*". Additionally, a single asterisk ("*") can serve as a default by matching any line not matched by any other pattern.

	<entry key="*" value-ref="defaultLineTokenizer" />


There is also a PatternMatchingCompositeLineTokenizer that can be used for tokenization alone.

It is also common for a flat file to contain records that each span multiple lines. To handle this situation, a more complex strategy is required. A demonstration of this common pattern can be found in Section 11.5, “Multi-Line Records”.

**Exception Handling in Flat Files**

There are many scenarios when tokenizing a line may cause exceptions to be thrown. Many flat files are imperfect and contain records that aren't formatted correctly. Many users choose to skip these erroneous lines, logging out the issue, original line, and line number. These logs can later be inspected manually or by another batch job. For this reason, Spring Batch provides a hierarchy of exceptions for handling parse exceptions: FlatFileParseException and FlatFileFormatException. FlatFileParseException is thrown by the FlatFileItemReader when any errors are encountered while trying to read a file. FlatFileFormatException is thrown by implementations of the LineTokenizer interface, and indicates a more specific error encountered while tokenizing.

**IncorrectTokenCountException**

Both DelimitedLineTokenizer and FixedLengthLineTokenizer have the ability to specify column names that can be used for creating a FieldSet. However, if the number of column names doesn't match the number of columns found while tokenizing a line the FieldSet can't be created, and a IncorrectTokenCountException is thrown, which contains the number of tokens encountered, and the number expected:

	tokenizer.setNames(new String[] {"A", "B", "C", "D"});
	
	try {
	    tokenizer.tokenize("a,b,c");
	}
	catch(IncorrectTokenCountException e){
	    assertEquals(4, e.getExpectedCount());
	    assertEquals(3, e.getActualCount());
	}


Because the tokenizer was configured with 4 column names, but only 3 tokens were found in the file, an IncorrectTokenCountException was thrown.

**IncorrectLineLengthException**

Files formatted in a fixed length format have additional requirements when parsing because, unlike a delimited format, each column must strictly adhere to its predefined width. If the total line length doesn't add up to the widest value of this column, an exception is thrown:

	tokenizer.setColumns(new Range[] { new Range(1, 5),
	                                   new Range(6, 10),
	                                   new Range(11, 15) });
	try {
	    tokenizer.tokenize("12345");
	    fail("Expected IncorrectLineLengthException");
	}
	catch (IncorrectLineLengthException ex) {
	    assertEquals(15, ex.getExpectedLength());
	    assertEquals(5, ex.getActualLength());
	}


The configured ranges for the tokenizer above are: 1-5, 6-10, and 11-15, thus the total length of the line expected is 15. However, in this case a line of length 5 was passed in, causing an IncorrectLineLengthException to be thrown. Throwing an exception here rather than only mapping the first column allows the processing of the line to fail earlier, and with more information than it would if it failed while trying to read in column 2 in a FieldSetMapper. However, there are scenarios where the length of the line isn't always constant. For this reason, validation of line length can be turned off via the 'strict' property:


	tokenizer.setColumns(new Range[] { new Range(1, 5), new Range(6, 10) });
	tokenizer.setStrict(false);
	FieldSet tokens = tokenizer.tokenize("12345");
	assertEquals("12345", tokens.readString(0));
	assertEquals("", tokens.readString(1));


上面示例和前一个几乎完全相同, 只是调用了 `tokenizer.setStrict(false)` 。这个设置告诉 tokenizer 在对一行进行解析(tokenizing)时不要去管(enforce)行的长度。然后就正确地创建了一个 FieldSet并返回。当然,剩下的值就只会包含空的token值。

